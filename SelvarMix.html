<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>SelvarMix</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/journal.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-1.1/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-1.1/highlight.js"></script>
<link href="site_libs/ionicons-2.0.1/css/ionicons.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 61px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 66px;
  margin-top: -66px;
}

.section h2 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h3 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h4 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h5 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h6 {
  padding-top: 66px;
  margin-top: -66px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Acceuil</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="recherche.html">Recherche</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="ion ion-easel"></span>
     
    Enseignements
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">M2R santé publique</li>
    <li>
      <a href="MANprobastat.html">Mise à niveau probabilité et statistiques</a>
    </li>
    <li>
      <a href="MANmatrice.html">Mise à niveau Matrices</a>
    </li>
    <li>
      <a href="ml.html">Modèle linéaire</a>
    </li>
    <li>
      <a href="statmath.html">Statistique mathématique</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">M2 MathSV</li>
    <li>
      <a href="genpops.html">Modèles de génétique des populations neutre</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="ion ion-settings"></span>
     
    Packages et logiciels
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Model selection in model-based clustering</li>
    <li>
      <a href="VarSelLCM.html">Exact ICL optimization</a>
    </li>
    <li>
      <a href="npdataclustering.html">Model selection in mixed data clustering</a>
    </li>
    <li>
      <a href="SelvarMix.html">Lasso regularization</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Model Selection in Binary data</li>
    <li>
      <a href="MHTrajectoryR.html">Logistic binary data regression</a>
    </li>
    <li>
      <a href="MvBinary.html">Modeling high-dimensional binary data</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore"><strong>SelvarMix</strong></h1>

</div>


<p><em>SelvarMix: A R package for variable selection in model-based clustering and discriminant analysis with a regularization approach.</em></p>
<p><strong>Description:</strong></p>
<ul>
<li><em>Authors</em>: <strong>Gilles Celeux</strong> and <strong>Cathy Maugis-Rabusseau</strong> and <strong>Mohammed A. Sedki</strong>.</li>
<li><em>License</em>: <a href="http://www.gnu.org/licenses/gpl-2.0.html">GPL-2</a>.</li>
<li><p><em>Download SelvarMix 1.2 (beta version)</em>: <a href="http://r-forge.r-project.org/R/?group_id=2044">link</a>.</p></li>
<li><em>Download SelvarMix 1.1 (cran version)</em>: <a href="http://cran.r-project.org/web/packages/SelvarMix/">link</a>.</li>
<li><p><em>Reference</em>: <a href="https://hal.archives-ouvertes.fr/hal-01053784/">SelvarMix: A R package for variable selection in model-based clustering and discriminant analysis with a regularization approach</a>, Celeux, G., and Maugis-Rabusseau, C. and Sedki, M. 2016, preprint.</p></li>
</ul>
<p><a id="top"></a> <strong>Site map:</strong></p>
<ul>
<li><a href="#intro">Introduction</a>.</li>
<li><a href="#dataset">Synthetic dataset</a>.</li>
<li><a href="#clust">Variable selection in model-based clustering</a>.</li>
<li><a href="#discrim">Variable selection in classification</a>.</li>
</ul>
<p>All the experiments are implemented with SelvarMix 1.2 <a id="intro"></a></p>
<div id="introduction" class="section level3">
<h3>Introduction</h3>
<p><em>SelvarMix</em> package carries out a regularization approach of variable selection in the model-based clustering and classification frameworks. First, the variables are ranked with a lasso-like procedure. Second, the method of <span class="citation">(Maugis, Celeux, and Martin-Magniette 2009; Maugis, Celeux, and Martin-Magniette 2011)</span> is adapted to define the role of variables in the two frameworks. This variable ranking allows us to avoid the painfully slow stepwise forward or backward algorithms of <span class="citation">(Maugis, Celeux, and Martin-Magniette 2009)</span>. Thus, SelvarMix provides a much faster variable selection procedure than <span class="citation">(Maugis, Celeux, and Martin-Magniette 2009; Maugis, Celeux, and Martin-Magniette 2011)</span> allowing to study high-dimensional datasets.</p>
<p>Tool functions <em>summary and print</em> facilitate the result interpretation.</p>
</div>
<div id="overview-of-the-selvarmix-functions" class="section level3">
<h3>Overview of the SelvarMix functions</h3>
<p>This section presents the whole analysis of a simulated data set. It makes use all the functions implemented in the package <em>SelvarMix</em> and may be regarded as a tutorial.</p>
<p>The cluster analysis is performed with an unknown number of clusters. An information criterion is used for variable selection and choosing the number of clusters. The chosen model is described in a summary.</p>
<p><strong>The synthetic dataset</strong></p>
<p>The simulated dataset consists of 2000 data points in <span class="math inline">\(\mathbb{R}^{14}\)</span>. On the subset of relevant clustering variables <span class="math inline">\(S = \{1, 2\}\)</span>, data are distributed according to a mixture of four equiprobable spherical Gaussian distributions with means <span class="math inline">\((0,0), (3,0)  (0,3)\)</span> and <span class="math inline">\((3,3)\)</span>. The subset of redundant variables is <span class="math inline">\(U =\{3-11\}\)</span>. These variables are explained by the subset of predictor variables <span class="math inline">\(R = \{1,2\}\)</span> through a linear regression. The last three variables <span class="math inline">\(W = \{12, 13, 14\}\)</span> are independent. More details are given in <span class="citation">(Maugis, Celeux, and Martin-Magniette 2009)</span>.</p>
<p><a id="tutorial"></a></p>
<pre class="r"><code>set.seed(123)
n &lt;- 2000; p &lt;- 14
x &lt;- matrix(0,n, p)
x[,1] &lt;- rnorm(n,0,1)
x[,2] &lt;- rnorm(n,0,1)
z &lt;-  sample(1:4, n, rep=T)
x[z==2, 1] &lt;- x[z==2, 1] + 3
x[z==3, 2] &lt;- x[z==3, 2] + 3
x[z==4, 1] &lt;- x[z==4, 1] + 3
x[z==4, 2] &lt;- x[z==4, 2] + 3

omega &lt;- matrix(0, 9, 9); diag(omega)[1:3] &lt;- rep(1,3); diag(omega)[4:5] &lt;- rep(0.5,2)
rtmat1 &lt;- matrix(c(cos(pi/3), -sin(pi/3), sin(pi/3), cos(pi/3)), ncol = 2, byrow = TRUE)
rtmat2 &lt;- matrix(c(cos(pi/6), -sin(pi/6), sin(pi/6), cos(pi/6)), ncol = 2, byrow = TRUE)
omega[6:7, 6:7] &lt;- t(rtmat1) %*% diag(c(1,3)) %*% rtmat1
omega[8:9, 8:9] &lt;- t(rtmat2) %*% diag(c(2,6)) %*% rtmat2
b &lt;- cbind(c(0.5,1), c(2,0), c(0,3), c(-1,2), c(2,-4), c(0.5,0), c(4,0.5), c(3,0), c(2,1))
x[,3:11] &lt;- c(0, 0, seq(0.4, 2, len=7)) + x[,1:2]%*%b + t(t(chol(omega)) %*% matrix(rnorm(n*9), 9, n)) 
x[,12:14] &lt;- matrix(rnorm(3*n), n, 3)
x[,12] &lt;- x[,12] + 3.2; x[,13] &lt;- x[,13] + 3.6; x[,13] &lt;- x[,13] + 4</code></pre>
<ul>
<li><a href="#top">Go to the top</a></li>
</ul>
<p><a id="clust"></a> <strong>Variable selection and selection of the number of clusters in the clustering framework</strong></p>
<pre class="r"><code># Cluster analysis with variable selection with parallel computing (8 cores) 
# The last two input arguments are optional
require(SelvarMix)</code></pre>
<pre><code>Loading required package: SelvarMix</code></pre>
<pre><code>Loading required package: glasso</code></pre>
<pre><code>Loading required package: Rmixmod</code></pre>
<pre><code>Loading required package: Rcpp</code></pre>
<pre><code>Rmixmod version 2.1.1 loaded
R package of mixmodLib version 3.2.2

Condition of use
----------------
Copyright (C)  MIXMOD Team - 2001-2013

MIXMOD is publicly available under the GPL license (see www.gnu.org/copyleft/gpl.html)
You can redistribute it and/or modify it under the terms of the GPL-3 license.
Please understand that there may still be bugs and errors. Use it at your own risk.
We take no responsibility for any errors or omissions in this package or for any misfortune that may befall you or others as a result of its use.

Please report bugs at: http://www.mixmod.org/article.php3?id_article=23

More information on : www.mixmod.org</code></pre>
<pre><code>Loading required package: parallel</code></pre>
<pre class="r"><code>obj &lt;- SelvarClustLasso(x=x, nbcluster=3:5, models=mixmodGaussianModel(family = &quot;spherical&quot;), nbcores=8)</code></pre>
<pre><code>variable  ranking
SRUW selection with BIC criterion
model selection  with BIC criterion</code></pre>
<p><strong>Model Summary</strong></p>
<pre class="r"><code># Summary of the selected model
summary(obj)</code></pre>
<pre><code>Criterion: BIC 
Criterion value: -94401.89 
Number of clusters: 4 
Gaussian mixture model: Gaussian_p_L_I 
Regression covariance model: LC 
Independent covariance model: LI 
The SRUW model:
 S: 1 2 
 R: 1 2 
 U: 3 4 5 6 7 8 9 10 11 
 W: 14 13 12 </code></pre>
<ul>
<li><a href="#top">Go to the top</a></li>
</ul>
<p><strong>Result print</strong></p>
<pre class="r"><code># print clustering and regression parameters 
print(obj)</code></pre>
<pre><code>$S
[1] 1 2

$R
[1] 1 2

$U
[1]  3  4  5  6  7  8  9 10 11

$W
[1] 14 13 12

$criterionValue
[1] -94401.89

$criterion
[1] &quot;BIC&quot;

$model
[1] &quot;Gaussian_p_L_I&quot;

$rmodel
[1] &quot;LC&quot;

$imodel
[1] &quot;LI&quot;

$parameters
****************************************
*** Cluster 1 
* proportion =  0.2500 
* means      =  3.0356 0.0090 
* variances  = |     0.9686     0.0000 |
               |     0.0000     0.9686 |
*** Cluster 2 
* proportion =  0.2500 
* means      =  2.9659 2.8863 
* variances  = |     0.9686     0.0000 |
               |     0.0000     0.9686 |
*** Cluster 3 
* proportion =  0.2500 
* means      =  0.0399 3.0213 
* variances  = |     0.9686     0.0000 |
               |     0.0000     0.9686 |
*** Cluster 4 
* proportion =  0.2500 
* means      =  0.0225 -0.0615 
* variances  = |     0.9686     0.0000 |
               |     0.0000     0.9686 |
****************************************

$nbcluster
[1] 4

$partition
   [1] 3 1 2 4 3 2 4 1 3 3 2 2 3 1 3 1 4 3 2 4 2 2 2 2 4 4 4 1 3 3 2 2 1 3
  [35] 4 2 3 3 4 2 2 2 4 1 3 4 4 4 1 3 2 4 2 2 4 4 4 3 3 3 4 4 3 4 4 3 4 4
  [69] 1 1 4 4 2 3 1 4 1 4 2 4 2 1 1 4 3 1 2 3 1 2 4 1 2 2 4 1 1 1 1 2 1 2
 [103] 4 1 1 4 2 3 1 2 1 2 4 4 4 4 3 3 3 2 2 1 4 1 2 2 1 2 3 3 4 1 3 3 4 1
 [137] 3 4 1 4 3 1 4 3 3 2 2 1 2 2 2 2 4 3 1 3 1 3 2 3 1 1 1 1 2 4 2 2 4 1
 [171] 1 1 4 2 1 3 1 1 2 2 3 3 3 3 3 1 1 1 2 1 3 3 4 1 1 1 1 2 1 2 2 3 2 2
 [205] 4 4 3 4 1 1 1 1 3 2 1 1 4 4 4 3 1 4 3 1 3 4 4 4 3 1 1 4 1 2 3 4 4 1
 [239] 4 3 1 2 3 1 2 1 1 4 4 1 1 3 1 4 1 1 3 2 2 4 2 1 1 2 2 1 2 4 1 2 3 3
 [273] 3 1 1 2 3 1 3 2 4 3 1 1 1 2 3 1 1 4 1 1 3 3 1 2 1 2 2 1 4 2 3 2 4 1
 [307] 3 4 3 1 4 3 3 1 3 2 1 4 2 4 3 4 4 3 4 1 3 1 3 1 1 4 4 4 4 3 3 3 2 2
 [341] 3 4 1 1 1 4 2 3 3 4 1 3 2 4 3 3 2 4 4 1 3 4 2 3 3 2 2 4 3 4 1 4 1 2
 [375] 4 3 1 2 1 4 2 1 1 1 2 3 2 3 1 3 2 3 3 4 1 1 3 3 4 4 3 4 4 1 2 3 4 4
 [409] 4 2 1 3 4 3 1 3 1 3 3 4 1 3 3 1 2 4 2 2 2 4 4 2 4 4 4 2 1 2 3 1 4 1
 [443] 3 2 3 2 3 1 4 4 1 3 1 3 3 3 2 4 4 1 1 3 3 4 2 4 1 1 3 1 1 1 2 1 4 1
 [477] 1 4 4 2 1 3 3 1 3 2 2 2 2 1 3 2 4 2 3 4 3 4 4 3 3 1 3 3 3 4 2 3 3 2
 [511] 3 2 1 3 3 1 4 1 3 3 1 2 2 3 1 4 4 1 2 2 1 1 3 1 2 3 2 2 4 3 4 1 1 2
 [545] 4 2 4 4 2 4 1 2 2 3 2 2 2 2 1 3 2 4 4 1 3 2 3 4 1 1 2 1 4 4 1 2 3 3
 [579] 3 4 3 4 2 1 4 3 4 4 2 4 4 1 3 3 3 2 1 4 2 2 2 2 2 4 3 2 3 1 3 1 1 2
 [613] 2 1 2 3 3 4 3 1 4 3 3 1 4 2 1 2 1 2 2 4 1 1 1 3 4 1 3 1 2 3 1 2 2 2
 [647] 1 1 4 2 3 4 2 3 4 4 4 1 3 4 3 2 1 2 4 2 3 1 2 1 1 3 2 2 1 4 1 1 2 3
 [681] 1 4 3 2 4 4 3 2 1 3 3 2 4 1 4 1 4 3 2 4 4 3 1 1 2 2 2 1 1 1 2 3 3 4
 [715] 1 3 4 1 4 3 1 3 4 3 4 3 1 3 2 2 2 1 3 1 1 3 2 4 3 2 1 1 1 1 1 4 2 2
 [749] 2 3 2 3 1 2 2 4 1 1 4 1 4 1 4 3 2 3 2 3 3 2 3 1 1 4 4 2 4 4 4 3 1 3
 [783] 1 4 3 3 2 4 3 2 4 3 3 4 1 1 1 2 4 4 1 3 4 3 3 3 4 1 2 1 4 3 1 3 4 2
 [817] 1 2 2 3 1 2 3 3 4 3 2 3 3 3 4 3 3 1 1 3 3 1 3 1 3 1 2 4 2 4 3 3 2 1
 [851] 3 3 2 3 2 2 3 1 3 1 3 4 2 2 3 2 3 4 2 1 3 1 3 4 4 2 2 1 4 4 2 3 4 3
 [885] 4 2 2 1 2 1 4 3 2 1 4 2 4 4 4 3 1 4 3 2 1 1 2 2 1 4 2 4 4 3 4 3 4 4
 [919] 4 2 3 4 2 3 4 2 4 1 1 3 2 1 3 1 3 4 2 3 3 3 3 3 4 3 1 3 1 2 4 4 4 3
 [953] 2 2 4 3 1 1 2 3 3 2 3 2 3 3 4 4 4 1 2 4 3 2 1 2 2 4 3 3 1 3 2 4 2 3
 [987] 1 1 1 1 2 1 1 1 3 4 3 2 1 2
 [ reached getOption(&quot;max.print&quot;) -- omitted 1000 entries ]

$proba
                [,1]         [,2]         [,3]         [,4]
   [1,] 7.059802e-05 2.008090e-03 9.588056e-01 3.911571e-02
   [2,] 9.533252e-01 2.657663e-02 3.960810e-04 1.970211e-02
   [3,] 2.397186e-02 5.355320e-01 4.222553e-01 1.824089e-02
   [4,] 8.050154e-03 5.043017e-03 2.998680e-01 6.870389e-01
   [5,] 7.224280e-05 1.499412e-02 9.804796e-01 4.454082e-03
   [6,] 6.534741e-02 9.345972e-01 5.270515e-05 2.719246e-06
   [7,] 3.069555e-02 2.331774e-06 2.795403e-05 9.692742e-01
   [8,] 6.434784e-01 1.412611e-03 4.243533e-04 3.546846e-01
   [9,] 1.686770e-04 1.300988e-03 8.555279e-01 1.430024e-01
  [10,] 1.164657e-04 2.839095e-03 9.517349e-01 4.530952e-02
  [11,] 1.150379e-01 8.847265e-01 2.132225e-04 2.240736e-05
  [12,] 1.457844e-03 9.945231e-01 4.015342e-03 3.748671e-06
  [13,] 7.178635e-05 3.231107e-02 9.657518e-01 1.865379e-03
  [14,] 8.825301e-01 1.107524e-01 6.332926e-04 6.084225e-03
  [15,] 3.535866e-05 2.012574e-03 9.789672e-01 1.898486e-02
  [16,] 5.090551e-01 2.115552e-01 6.948864e-02 2.099011e-01
  [17,] 3.586063e-02 1.788055e-05 2.094575e-04 9.639120e-01
  [18,] 2.234206e-07 2.779906e-05 9.904693e-01 9.502710e-03
  [19,] 7.794476e-02 9.208823e-01 1.096537e-03 7.645513e-05
  [20,] 1.924212e-03 2.531768e-04 7.208658e-02 9.257360e-01
  [21,] 4.855889e-03 7.764708e-01 2.175723e-01 1.101037e-03
  [22,] 3.532086e-04 9.755929e-01 2.404864e-02 5.301397e-06
  [23,] 1.541108e-05 7.557569e-01 2.442250e-01 2.666256e-06
  [24,] 5.606017e-03 9.029379e-01 9.101361e-02 4.425170e-04
  [25,] 1.181486e-03 4.249821e-06 1.617861e-03 9.971964e-01
  [26,] 3.251036e-01 4.311967e-04 4.515072e-04 6.740137e-01
  [27,] 1.022565e-01 7.418176e-04 3.532699e-03 8.934690e-01
  [28,] 9.829297e-01 1.072312e-02 4.806476e-05 6.299140e-03
  [29,] 5.124914e-09 2.578909e-04 9.997278e-01 1.427471e-05
  [30,] 6.986749e-02 2.785553e-01 5.083175e-01 1.432597e-01
  [31,] 2.080833e-01 7.893802e-01 2.042660e-03 4.938033e-04
  [32,] 3.087653e-02 9.446786e-01 2.378704e-02 6.578502e-04
  [33,] 9.315343e-01 6.786397e-02 3.546296e-05 5.662721e-04
  [34,] 8.798726e-05 1.182568e-01 8.811515e-01 5.037203e-04
  [35,] 9.401202e-02 1.005294e-04 4.595231e-04 9.054279e-01
  [36,] 7.098400e-03 9.915171e-01 1.377657e-03 6.818434e-06
  [37,] 5.046137e-04 5.331164e-02 9.377489e-01 8.434890e-03
  [38,] 1.690767e-06 7.387446e-03 9.924354e-01 1.754255e-04
  [39,] 2.785439e-03 1.218378e-03 2.218562e-01 7.741400e-01
  [40,] 2.310369e-02 9.450449e-01 3.121381e-02 6.375813e-04
  [41,] 7.505347e-03 9.102913e-01 8.166699e-02 5.363564e-04
  [42,] 1.375316e-03 9.766907e-01 2.191326e-02 2.068328e-05
  [43,] 1.489455e-04 2.020642e-08 4.554465e-05 9.998055e-01
  [44,] 8.728647e-01 5.000507e-03 4.241178e-04 1.217107e-01
  [45,] 4.322519e-04 2.729966e-01 7.256682e-01 9.029629e-04
  [46,] 2.513328e-04 9.692652e-07 1.664038e-03 9.980837e-01
  [47,] 2.424025e-03 3.515262e-05 7.308257e-03 9.902326e-01
  [48,] 1.992428e-03 3.258334e-05 8.257991e-03 9.897170e-01
  [49,] 9.975540e-01 1.490550e-03 9.186712e-07 9.545585e-04
  [50,] 1.205934e-03 7.896497e-03 8.340263e-01 1.568713e-01
  [51,] 1.790553e-02 9.771939e-01 4.832364e-03 6.823309e-05
  [52,] 7.600716e-03 4.572671e-05 2.947889e-03 9.894057e-01
  [53,] 8.192621e-04 9.854011e-01 1.377235e-02 7.276399e-06
  [54,] 1.164446e-04 9.996670e-01 2.165488e-04 1.217928e-08
  [55,] 4.207446e-03 6.947444e-05 8.515634e-03 9.872074e-01
  [56,] 4.783257e-01 2.359422e-02 1.585865e-02 4.822215e-01
  [57,] 6.874893e-05 1.049424e-06 6.942808e-03 9.929874e-01
  [58,] 7.539294e-05 5.387675e-02 9.449549e-01 1.092980e-03
  [59,] 6.194195e-05 1.467272e-02 9.813938e-01 3.871571e-03
  [60,] 7.750038e-05 1.924435e-02 9.770455e-01 3.632602e-03
  [61,] 2.241648e-02 1.001469e-02 2.306016e-01 7.369672e-01
  [62,] 1.675850e-03 1.556567e-06 3.839844e-04 9.979386e-01
  [63,] 3.344246e-07 3.156069e-03 9.967644e-01 7.922446e-05
  [64,] 3.615977e-04 1.847509e-05 2.612119e-02 9.734987e-01
  [65,] 3.060370e-04 9.520989e-06 1.544240e-02 9.842420e-01
  [66,] 1.151277e-03 2.663311e-02 9.286697e-01 4.354588e-02
  [67,] 3.298773e-02 3.304126e-04 5.175969e-03 9.615059e-01
  [68,] 1.002728e-02 5.102227e-04 2.842863e-02 9.610339e-01
  [69,] 9.992953e-01 2.759371e-05 9.178390e-09 6.771140e-04
  [70,] 8.272187e-01 2.012110e-03 2.346619e-04 1.705345e-01
  [71,] 1.840502e-03 1.829852e-04 5.432970e-02 9.436468e-01
  [72,] 6.716155e-02 4.484845e-04 3.314795e-03 9.290752e-01
  [73,] 1.032510e-01 8.962896e-01 4.198403e-04 3.956574e-05
  [74,] 6.437436e-05 1.280143e-03 9.414902e-01 5.716526e-02
  [75,] 8.958235e-01 2.571901e-02 1.528040e-03 7.692947e-02
  [76,] 1.566504e-01 1.904924e-05 4.248503e-05 8.432880e-01
  [77,] 8.256818e-01 1.520874e-01 2.920253e-03 1.931058e-02
  [78,] 1.648565e-04 4.821553e-09 8.836909e-06 9.998263e-01
  [79,] 4.272333e-02 9.514622e-01 5.606270e-03 2.082396e-04
  [80,] 5.246583e-03 8.605683e-06 7.281822e-04 9.940166e-01
  [81,] 2.860702e-01 7.050253e-01 6.362928e-03 2.541533e-03
  [82,] 9.961253e-01 5.345953e-04 1.033250e-06 3.339064e-03
  [83,] 9.416958e-01 2.757471e-02 6.293643e-04 3.010013e-02
  [84,] 5.920075e-02 6.665006e-04 5.808157e-03 9.343246e-01
  [85,] 1.065910e-04 5.533274e-03 9.741640e-01 2.019614e-02
  [86,] 9.063007e-01 9.027990e-02 2.620467e-04 3.157304e-03
  [87,] 3.545614e-01 6.451189e-01 2.133194e-04 1.063143e-04
  [88,] 4.661451e-04 3.819698e-02 9.499905e-01 1.134637e-02
  [89,] 9.697139e-01 9.918352e-04 1.689761e-05 2.927737e-02
  [90,] 1.031870e-01 8.965149e-01 2.727195e-04 2.533000e-05
  [91,] 1.331292e-01 4.714110e-02 1.684242e-01 6.513055e-01
  [92,] 9.767147e-01 2.145599e-02 3.017432e-05 1.799167e-03
  [93,] 1.825723e-01 8.129189e-01 3.734649e-03 7.741588e-04
  [94,] 3.447088e-02 9.019037e-01 6.154788e-02 2.077557e-03
  [95,] 3.658386e-01 2.395203e-03 2.343337e-03 6.294229e-01
  [96,] 9.329929e-01 1.751282e-03 7.024774e-05 6.518560e-02
  [97,] 9.993271e-01 6.606820e-04 5.607876e-09 1.221021e-05
  [98,] 9.896058e-01 1.030677e-02 7.180664e-07 8.673899e-05
  [99,] 8.718172e-01 1.087456e-01 1.767995e-03 1.766925e-02
 [100,] 3.744685e-03 7.960135e-01 1.995006e-01 7.412230e-04
 [101,] 9.062983e-01 7.139080e-03 4.270801e-04 8.613550e-02
 [102,] 3.171340e-03 9.915521e-01 5.265131e-03 1.145133e-05
 [103,] 3.790798e-03 6.867944e-04 1.003393e-01 8.951832e-01
 [104,] 9.615850e-01 8.809552e-03 1.775659e-04 2.942792e-02
 [105,] 7.963078e-01 4.479715e-02 6.085706e-03 1.528093e-01
 [106,] 6.837329e-03 3.841435e-06 2.328601e-04 9.929260e-01
 [107,] 1.737471e-02 8.813074e-01 9.963830e-02 1.679613e-03
 [108,] 1.749067e-06 7.066422e-05 9.697461e-01 3.018154e-02
 [109,] 9.446707e-01 2.354943e-02 5.490692e-04 3.123081e-02
 [110,] 3.656496e-03 9.956295e-01 7.122964e-04 1.686873e-06
 [111,] 9.325963e-01 9.132221e-03 3.671824e-04 5.790428e-02
 [112,] 9.167517e-02 9.067847e-01 1.419360e-03 1.207847e-04
 [113,] 3.719597e-01 3.580892e-04 3.001029e-04 6.273821e-01
 [114,] 7.180177e-03 2.775434e-04 2.118365e-02 9.713586e-01
 [115,] 2.696982e-02 2.461898e-02 3.844982e-01 5.639130e-01
 [116,] 2.031269e-02 3.228389e-05 7.229536e-04 9.789321e-01
 [117,] 3.736153e-04 1.476364e-02 9.590426e-01 2.582012e-02
 [118,] 4.166599e-06 1.455231e-03 9.957538e-01 2.786832e-03
 [119,] 3.283409e-05 8.391832e-04 9.542523e-01 4.487571e-02
 [120,] 5.133911e-03 7.981009e-01 1.957485e-01 1.016748e-03
 [121,] 1.132532e-02 9.811428e-01 7.466773e-03 6.509483e-05
 [122,] 8.272502e-01 1.197206e-03 1.352618e-04 1.714174e-01
 [123,] 1.762620e-03 3.633160e-04 1.114678e-01 8.864062e-01
 [124,] 8.367328e-01 1.428299e-01 2.506158e-03 1.793112e-02
 [125,] 3.083714e-04 7.066976e-01 2.929078e-01 8.623041e-05
 [126,] 2.004848e-04 9.143070e-01 8.548106e-02 1.147536e-05
 [127,] 9.919663e-01 2.939393e-03 9.676339e-06 5.084601e-03
 [128,] 3.788974e-02 9.541325e-01 7.723758e-03 2.539888e-04
 [129,] 1.915605e-06 5.570270e-04 9.959438e-01 3.497255e-03
 [130,] 9.510814e-06 7.759595e-03 9.911722e-01 1.058734e-03
 [131,] 4.273053e-01 2.363580e-03 1.781045e-03 5.685501e-01
 [132,] 9.936990e-01 3.709919e-03 6.431353e-06 2.584645e-03
 [133,] 6.163383e-04 1.222904e-02 9.342126e-01 5.294201e-02
 [134,] 2.281994e-07 2.400231e-03 9.975283e-01 7.119117e-05
 [135,] 1.206833e-05 1.368018e-10 2.957524e-06 9.999850e-01
 [136,] 9.921519e-01 7.540759e-03 1.737444e-06 3.055892e-04
 [137,] 8.168161e-07 1.269335e-04 9.927193e-01 7.152959e-03
 [138,] 7.375770e-02 5.055782e-05 2.895468e-04 9.259022e-01
 [139,] 7.390790e-01 3.407331e-02 6.981414e-03 2.198662e-01
 [140,] 8.355907e-05 4.523309e-09 1.673391e-05 9.998997e-01
 [141,] 3.541440e-05 7.174460e-02 9.278725e-01 3.475184e-04
 [142,] 9.743565e-01 9.623960e-05 1.212159e-06 2.554600e-02
 [143,] 5.511688e-05 1.495342e-09 7.886310e-06 9.999370e-01
 [144,] 7.712295e-06 1.111556e-04 9.151807e-01 8.470048e-02
 [145,] 3.602376e-07 8.170501e-05 9.950718e-01 4.846131e-03
 [146,] 5.921979e-02 8.937514e-01 4.435395e-02 2.674825e-03
 [147,] 2.451000e-02 5.202764e-01 4.353117e-01 1.990193e-02
 [148,] 9.652999e-01 3.352961e-02 3.162387e-05 1.138892e-03
 [149,] 2.116769e-01 7.883073e-01 1.305821e-05 2.745977e-06
 [150,] 7.569356e-03 6.475652e-01 3.414173e-01 3.448093e-03
 [151,] 2.387520e-03 9.965300e-01 1.080881e-03 1.640052e-06
 [152,] 8.177067e-05 9.985754e-01 1.342769e-03 5.480945e-08
 [153,] 2.345681e-02 1.601673e-03 3.896467e-02 9.359768e-01
 [154,] 1.811797e-08 3.966333e-04 9.995690e-01 3.439008e-05
 [155,] 9.367107e-01 4.924454e-02 5.413369e-04 1.350346e-02
 [156,] 3.557826e-05 4.490294e-03 9.875260e-01 7.948139e-03
 [157,] 9.978873e-01 1.594638e-05 1.528652e-08 2.096785e-03
 [158,] 8.650500e-04 2.918944e-03 7.149674e-01 2.812486e-01
 [159,] 2.674559e-02 9.727121e-01 5.315262e-04 1.082225e-05
 [160,] 2.897262e-06 3.084045e-03 9.960895e-01 8.235704e-04
 [161,] 9.948039e-01 4.798937e-03 1.372187e-06 3.957527e-04
 [162,] 7.432677e-01 5.466285e-02 1.009412e-02 1.919753e-01
 [163,] 6.408148e-01 4.036892e-04 1.126863e-04 3.586689e-01
 [164,] 9.892407e-01 5.841098e-03 1.952520e-05 4.898718e-03
 [165,] 4.843618e-03 9.570273e-01 3.798505e-02 1.440300e-04
 [166,] 2.071063e-02 1.173152e-04 2.813347e-03 9.763587e-01
 [167,] 7.372929e-03 9.910104e-01 1.608328e-03 8.336125e-06
 [168,] 6.306397e-02 8.960100e-01 3.846256e-02 2.463462e-03
 [169,] 4.104475e-02 2.023911e-03 2.777487e-02 9.291565e-01
 [170,] 9.864987e-01 1.024194e-02 2.389688e-05 3.235480e-03
 [171,] 9.687180e-01 1.160419e-02 1.589594e-04 1.951887e-02
 [172,] 9.903876e-01 4.092337e-05 1.841736e-07 9.571303e-03
 [173,] 7.312131e-03 1.667725e-05 1.044542e-03 9.916266e-01
 [174,] 4.916913e-01 5.082954e-01 7.278327e-06 6.026142e-06
 [175,] 4.837342e-01 4.354696e-01 3.572464e-02 4.507156e-02
 [176,] 1.279470e-05 3.986731e-04 9.621298e-01 3.745877e-02
 [177,] 9.826220e-01 8.244078e-03 5.173330e-05 9.082200e-03
 [178,] 9.664428e-01 2.976737e-02 8.719949e-05 3.702597e-03
 [179,] 3.993578e-04 9.962086e-01 3.391264e-03 7.834878e-07
 [180,] 2.447744e-03 9.532015e-01 4.426928e-02 8.145929e-05
 [181,] 1.359267e-07 3.704587e-04 9.993072e-01 3.221680e-04
 [182,] 1.372475e-02 3.277439e-01 6.323713e-01 2.616000e-02
 [183,] 7.315306e-05 3.754185e-03 9.754469e-01 2.072576e-02
 [184,] 1.996099e-07 6.664106e-04 9.990791e-01 2.543254e-04
 [185,] 4.019823e-05 5.124569e-03 9.870092e-01 7.826068e-03
 [186,] 5.807666e-01 4.029022e-01 6.320697e-03 1.001050e-02
 [187,] 9.986429e-01 1.011463e-03 2.261640e-07 3.454376e-04
 [188,] 7.824717e-01 2.104396e-01 1.348717e-03 5.739934e-03
 [189,] 6.042147e-02 9.385630e-01 9.656074e-04 4.996431e-05
 [190,] 9.203421e-01 3.484359e-02 1.186660e-03 4.362769e-02
 [191,] 1.533814e-04 1.967570e-02 9.728302e-01 7.340706e-03
 [192,] 1.395926e-04 4.084644e-03 9.586760e-01 3.709975e-02
 [193,] 1.110606e-02 6.549059e-05 2.909023e-03 9.859194e-01
 [194,] 8.241174e-01 3.817010e-02 4.336074e-03 1.333765e-01
 [195,] 6.113250e-01 1.698254e-02 6.597728e-03 3.650947e-01
 [196,] 6.848697e-01 3.151109e-01 6.454545e-06 1.288196e-05
 [197,] 9.912847e-01 7.112477e-03 8.104784e-06 1.594750e-03
 [198,] 8.686213e-02 6.160842e-01 2.594260e-01 3.762774e-02
 [199,] 9.155456e-01 2.124225e-02 9.909103e-04 6.222122e-02
 [200,] 7.824729e-04 6.970234e-01 3.019488e-01 2.453448e-04
 [201,] 1.324064e-05 9.999672e-01 1.958902e-05 9.907601e-11
 [202,] 1.259996e-02 3.611255e-01 6.057624e-01 2.051222e-02
 [203,] 2.449176e-02 9.528655e-01 2.217010e-02 4.726133e-04
 [204,] 7.487193e-04 9.968621e-01 2.388099e-03 1.070211e-06
 [205,] 1.700291e-03 1.326245e-03 3.441410e-01 6.528325e-01
 [206,] 1.859810e-03 4.578268e-06 1.092809e-03 9.970428e-01
 [207,] 9.357931e-07 8.906592e-04 9.981406e-01 9.677713e-04
 [208,] 1.295927e-03 4.247860e-06 1.468852e-03 9.972310e-01
 [209,] 5.767527e-01 4.945416e-04 1.831751e-04 4.225696e-01
 [210,] 9.097761e-01 7.892656e-02 7.291294e-04 1.056819e-02
 [211,] 9.750560e-01 1.799224e-02 9.162868e-05 6.860103e-03
 [212,] 9.549239e-01 4.046002e-02 1.471753e-04 4.468883e-03
 [213,] 1.508597e-02 3.073598e-01 6.457920e-01 3.176217e-02
 [214,] 4.337943e-05 9.373898e-01 6.256523e-02 1.565736e-06
 [215,] 7.482830e-01 7.866329e-02 1.244987e-02 1.606038e-01
 [216,] 9.960047e-01 3.937842e-03 1.702296e-07 5.726538e-05
 [217,] 2.114902e-03 2.963761e-04 7.693247e-02 9.206563e-01
 [218,] 8.303717e-04 3.991391e-07 1.858352e-04 9.989834e-01
 [219,] 1.810664e-04 2.212523e-06 5.641891e-03 9.941748e-01
 [220,] 2.030491e-08 1.797895e-04 9.997271e-01 9.313690e-05
 [221,] 9.341381e-01 7.535414e-03 2.989927e-04 5.802754e-02
 [222,] 5.061202e-02 1.218210e-02 1.327334e-01 8.044725e-01
 [223,] 3.930237e-03 2.343903e-01 7.498736e-01 1.180589e-02
 [224,] 9.050522e-01 9.388213e-02 8.784044e-05 9.778197e-04
 [225,] 3.749727e-04 3.517939e-03 8.804171e-01 1.156900e-01
 [226,] 1.023989e-02 3.325968e-04 1.777959e-02 9.716479e-01
 [227,] 5.654117e-04 7.357835e-04 4.695531e-01 5.291457e-01
 [228,] 8.836526e-04 2.686973e-06 1.340329e-03 9.977733e-01
 [229,] 4.821372e-04 1.282577e-01 8.684459e-01 2.814286e-03
 [230,] 7.932690e-01 6.588780e-04 8.907609e-05 2.059830e-01
 [231,] 7.775032e-01 5.551091e-04 8.135863e-05 2.218604e-01
 [232,] 6.101374e-03 1.026944e-05 7.514041e-04 9.931370e-01
 [233,] 5.592677e-01 4.360780e-01 1.985872e-03 2.668459e-03
 [234,] 5.165690e-04 8.955454e-01 1.038984e-01 3.964101e-05
 [235,] 2.260616e-06 1.716279e-03 9.970746e-01 1.206822e-03
 [236,] 1.188225e-04 6.043292e-05 2.342302e-01 7.655905e-01
 [237,] 4.692425e-03 2.268218e-05 2.306117e-03 9.929788e-01
 [238,] 8.860556e-01 1.113536e-01 2.511608e-04 2.339653e-03
 [239,] 2.300333e-02 7.050787e-04 1.691826e-02 9.593733e-01
 [240,] 1.610349e-04 9.427137e-04 8.143359e-01 1.845604e-01
 [241,] 8.863519e-01 1.077610e-03 7.477148e-05 1.124957e-01
 [242,] 7.801343e-03 9.444962e-01 4.739624e-02 3.062189e-04
 [243,] 2.342729e-03 4.839161e-01 5.116896e-01 2.051571e-03
 [244,] 7.306141e-01 4.140199e-03 8.843633e-04 2.643613e-01
 [245,] 1.566584e-01 8.273954e-01 1.351792e-02 2.428319e-03
 [246,] 8.502329e-01 1.497412e-01 3.903647e-06 2.199655e-05
 [247,] 9.412109e-01 4.548163e-02 4.709901e-04 1.283644e-02
 [248,] 1.221538e-04 9.431819e-07 3.417523e-03 9.964594e-01
 [249,] 1.076710e-03 9.716083e-05 4.850923e-02 9.503169e-01
 [250,] 5.028907e-01 4.950764e-01 1.006387e-03 1.026580e-03
 [ getOption(&quot;max.print&quot;) est atteint -- 1750 lignes omises ]

$regparameters
                  3           4          5          6          7
intercept 0.8955058  0.91583873  0.9756543  0.9668664  0.9979245
1         0.5086800  2.01156693 -0.0186641 -1.0231808  1.9828448
2         1.0166012 -0.02518655  3.0110172  2.0015700 -4.0198483
                     8         9         10        11
intercept  0.846165781 0.8630311 0.88161925 0.8946564
1          0.521229074 4.0049986 2.98323243 2.0136865
2         -0.008883697 0.5097855 0.01598624 1.0115493

attr(,&quot;class&quot;)
[1] &quot;selvarmix&quot;</code></pre>
<ul>
<li><a href="#top">Go to the top</a></li>
</ul>
<p><a id="discrim"></a> <strong>Variable selection in classification</strong></p>
<pre class="r"><code># Discriminant analysis with learning and testing data
# Variable selection with parallel computing (8 cores)
xl &lt;- x[1:1900,]; xt &lt;- x[1901:2000,] 
zl &lt;- z[1:1900]; zt &lt;- z[1901:2000]
obj &lt;- SelvarLearnLasso(x=xl, z=zl, models=mixmodGaussianModel(family = &quot;spherical&quot;), xtest=xt, ztest=zt,nbcores=8)</code></pre>
<pre><code>variable  ranking
SRUW  selection with BIC criterion
model selection with BIC criterion</code></pre>
<p><strong>Model Summary</strong></p>
<pre class="r"><code># Summary of the selected model
summary(obj)</code></pre>
<pre><code>Criterion: BIC 
Criterion value: -90917.73 
Number of clusters: 
Gaussian mixture model: Gaussian_p_L_I 
Prediction error: 0.14 
Regression covariance model: LC 
Independent covariance model: LI 
The SRUW model:
 S: 1 2 
 R: 1 2 
 U: 3 4 5 6 7 8 9 10 11 
 W: 14 13 12 </code></pre>
<ul>
<li><a href="#top">Go to the top</a></li>
</ul>
<p><strong>Result print</strong></p>
<pre class="r"><code># print clustering and regression parameters 
print(obj)</code></pre>
<pre><code>$S
[1] 1 2

$R
[1] 1 2

$U
[1]  3  4  5  6  7  8  9 10 11

$W
[1] 14 13 12

$criterionValue
[1] -90917.73

$criterion
[1] &quot;BIC&quot;

$model
[1] &quot;Gaussian_p_L_I&quot;

$rmodel
[1] &quot;LC&quot;

$imodel
[1] &quot;LI&quot;

$parameters
****************************************
*** Cluster 1 
* proportion =  0.2500 
* means      =  0.0348 -0.0533 
* variances  = |     0.9721     0.0000 |
               |     0.0000     0.9721 |
*** Cluster 2 
* proportion =  0.2500 
* means      =  2.9986 0.0349 
* variances  = |     0.9721     0.0000 |
               |     0.0000     0.9721 |
*** Cluster 3 
* proportion =  0.2500 
* means      =  0.0656 3.0287 
* variances  = |     0.9721     0.0000 |
               |     0.0000     0.9721 |
*** Cluster 4 
* proportion =  0.2500 
* means      =  3.0066 2.8858 
* variances  = |     0.9721     0.0000 |
               |     0.0000     0.9721 |
****************************************

$partition
  [1] 2 2 1 2 2 3 1 3 4 4 2 1 4 4 2 3 3 1 4 3 1 2 3 3 4 4 4 4 1 4 2 1 1 1 4
 [36] 3 4 1 1 3 2 4 1 4 4 3 4 4 1 4 1 1 4 2 4 1 3 3 3 2 4 2 3 3 1 2 4 2 4 4
 [71] 1 2 3 4 1 4 4 2 3 3 2 3 3 3 2 4 1 4 1 2 1 4 2 1 2 2 4 1 3 4

$proba
               [,1]         [,2]         [,3]         [,4]
  [1,] 6.185989e-05 6.886467e-01 2.733219e-05 3.112641e-01
  [2,] 4.203934e-02 9.498698e-01 2.347828e-04 7.856033e-03
  [3,] 8.365892e-01 8.107904e-03 1.535125e-01 1.790325e-03
  [4,] 3.582748e-01 5.510838e-01 3.137694e-02 5.926446e-02
  [5,] 3.033184e-02 9.675364e-01 3.983495e-05 2.091966e-03
  [6,] 5.063041e-04 2.526173e-09 9.994905e-01 3.157730e-06
  [7,] 9.540513e-01 4.330595e-02 2.459854e-03 1.828969e-04
  [8,] 2.531526e-03 2.264321e-06 9.968517e-01 6.144693e-04
  [9,] 9.012219e-05 5.646768e-04 2.199729e-01 7.793723e-01
 [10,] 3.596072e-07 3.428000e-03 1.721589e-04 9.963995e-01
 [11,] 5.825276e-02 9.397715e-01 7.097838e-05 1.904758e-03
 [12,] 8.954089e-01 3.977629e-04 1.041345e-01 5.884084e-05
 [13,] 4.441144e-08 1.423686e-04 6.587438e-04 9.991988e-01
 [14,] 1.692887e-03 1.412176e-01 1.176819e-02 8.453213e-01
 [15,] 7.054940e-03 9.849273e-01 3.905564e-05 7.978684e-03
 [16,] 2.484031e-04 1.456540e-04 7.506170e-01 2.489889e-01
 [17,] 1.070118e-01 2.449355e-03 8.725523e-01 1.798658e-02
 [18,] 9.993364e-01 6.262334e-04 3.727799e-05 5.411335e-08
 [19,] 1.553371e-03 4.280097e-02 4.230956e-02 9.133361e-01
 [20,] 2.589152e-04 2.978191e-05 9.387677e-01 6.094362e-02
 [21,] 9.998824e-01 7.003944e-06 1.105480e-04 1.706037e-09
 [22,] 3.910003e-04 9.929294e-01 1.809064e-06 6.677824e-03
 [23,] 2.299252e-04 2.552573e-04 6.127577e-01 3.867571e-01
 [24,] 7.016041e-03 9.710633e-05 9.829480e-01 9.938871e-03
 [25,] 2.844854e-05 2.027126e-03 2.263647e-02 9.753080e-01
 [26,] 1.280404e-08 9.247216e-05 3.047587e-04 9.996028e-01
 [27,] 3.306946e-06 7.718066e-04 7.674843e-03 9.915500e-01
 [28,] 1.096452e-05 1.908954e-03 9.509933e-03 9.885701e-01
 [29,] 8.814542e-01 7.603219e-02 3.816641e-02 4.347239e-03
 [30,] 2.525020e-02 2.208579e-01 8.291941e-02 6.709725e-01
 [31,] 1.546161e-02 8.457827e-01 2.158475e-03 1.365972e-01
 [32,] 6.894515e-01 2.577202e-01 3.564231e-02 1.718601e-02
 [33,] 8.942424e-01 7.318069e-02 2.933878e-02 3.238102e-03
 [34,] 9.896220e-01 1.999445e-04 1.017494e-02 3.152380e-06
 [35,] 4.128121e-04 3.111102e-01 9.935951e-04 6.874834e-01
 [36,] 5.291431e-03 1.037150e-06 9.945640e-01 1.434863e-04
 [37,] 1.164910e-05 2.547181e-04 8.105577e-02 9.186779e-01
 [38,] 7.273554e-01 2.710608e-01 9.704690e-04 6.133296e-04
 [39,] 9.243502e-01 7.561658e-02 2.801596e-05 5.213211e-06
 [40,] 1.649534e-01 7.916571e-02 5.197144e-01 2.361664e-01
 [41,] 2.155393e-04 9.971248e-01 3.686173e-07 2.659318e-03
 [42,] 2.977005e-05 3.329584e-04 1.430549e-01 8.565823e-01
 [43,] 6.381736e-01 2.940118e-01 4.286891e-02 2.494565e-02
 [44,] 9.825181e-07 8.268322e-05 2.485028e-02 9.750661e-01
 [45,] 2.736265e-05 1.214639e-02 3.220081e-03 9.846062e-01
 [46,] 1.835720e-02 2.748458e-03 8.766655e-01 1.022288e-01
 [47,] 3.168742e-06 6.157662e-05 9.996415e-02 8.999711e-01
 [48,] 2.535599e-03 1.122210e-01 2.297756e-02 8.622659e-01
 [49,] 9.735752e-01 2.775569e-03 2.355441e-02 9.483229e-05
 [50,] 9.817165e-09 6.455938e-03 2.439806e-06 9.935416e-01
 [51,] 8.995974e-01 1.387991e-02 8.487182e-02 1.650857e-03
 [52,] 9.613580e-01 3.753808e-02 1.033288e-03 7.063355e-05
 [53,] 5.479854e-05 2.453192e-03 3.485908e-02 9.626329e-01
 [54,] 2.420188e-02 9.750502e-01 1.023380e-05 7.376575e-04
 [55,] 3.202506e-06 2.522880e-02 1.728358e-04 9.745952e-01
 [56,] 8.975955e-01 3.370909e-03 9.856765e-02 4.659352e-04
 [57,] 8.416284e-02 1.076434e-03 9.045137e-01 1.024700e-02
 [58,] 5.373190e-04 2.361338e-05 9.738292e-01 2.560988e-02
 [59,] 1.702885e-03 6.160271e-06 9.959037e-01 2.387214e-03
 [60,] 1.251488e-05 5.154906e-01 1.231914e-05 4.844846e-01
 [61,] 4.405361e-02 6.342095e-02 3.965741e-01 4.959514e-01
 [62,] 1.885728e-01 8.090876e-01 2.895701e-04 2.049962e-03
 [63,] 2.415701e-03 1.104496e-05 9.944852e-01 3.088030e-03
 [64,] 2.533919e-01 1.795618e-01 3.306846e-01 2.363618e-01
 [65,] 8.104653e-01 1.713219e-01 1.404130e-02 4.171430e-03
 [66,] 6.227936e-04 9.973365e-01 7.931668e-07 2.039871e-03
 [67,] 1.052916e-04 1.683037e-01 6.076857e-04 8.309834e-01
 [68,] 1.733201e-01 3.759682e-01 1.385895e-01 3.121223e-01
 [69,] 2.754877e-03 3.086925e-02 1.001980e-01 8.661779e-01
 [70,] 9.559444e-04 1.896462e-01 4.611626e-03 8.047863e-01
 [71,] 7.442979e-01 2.413790e-01 9.784086e-03 4.538942e-03
 [72,] 1.145079e-01 8.853623e-01 7.609224e-06 1.222804e-04
 [73,] 6.616885e-03 4.334148e-05 9.886073e-01 4.732447e-03
 [74,] 1.829231e-06 2.590015e-02 9.631738e-05 9.740017e-01
 [75,] 9.914604e-01 3.127157e-04 8.222815e-03 4.029053e-06
 [76,] 7.884796e-10 2.230261e-06 1.043539e-03 9.989542e-01
 [77,] 9.469675e-04 3.962468e-01 1.511659e-03 6.012945e-01
 [78,] 2.228750e-01 7.331883e-01 8.316291e-03 3.562046e-02
 [79,] 2.548720e-01 3.857234e-04 7.436269e-01 1.115339e-03
 [80,] 4.774947e-02 6.342915e-03 8.510416e-01 9.486600e-02
 [81,] 5.437551e-03 9.933153e-01 4.006660e-06 1.243127e-03
 [82,] 3.954904e-03 3.946972e-03 5.818006e-01 4.102975e-01
 [83,] 1.365907e-04 3.163148e-07 9.985907e-01 1.272398e-03
 [84,] 2.531290e-02 1.698067e-06 9.746308e-01 5.458838e-05
 [85,] 4.877181e-04 9.988253e-01 1.915477e-07 6.867849e-04
 [86,] 4.326924e-04 8.234259e-03 7.042503e-02 9.209080e-01
 [87,] 9.883224e-01 1.166242e-02 1.475972e-05 4.233581e-07
 [88,] 2.250309e-05 4.495760e-01 2.931703e-05 5.503722e-01
 [89,] 7.786680e-01 3.932326e-03 2.161206e-01 1.279090e-03
 [90,] 8.771895e-05 9.489552e-01 3.874767e-06 5.095324e-02
 [91,] 9.997071e-01 2.841559e-04 8.755275e-06 6.460135e-09
 [92,] 8.236811e-07 1.770472e-03 7.973672e-04 9.974313e-01
 [93,] 4.321073e-03 8.996911e-01 3.875342e-04 9.560024e-02
 [94,] 9.968937e-01 9.943585e-04 2.108305e-03 3.589803e-06
 [95,] 3.335231e-01 6.373902e-01 8.128145e-03 2.095852e-02
 [96,] 9.686366e-03 9.901053e-01 1.029108e-06 2.073481e-04
 [97,] 8.923684e-07 2.635623e-04 6.638061e-03 9.930975e-01
 [98,] 6.843500e-01 1.748057e-02 2.898564e-01 8.313034e-03
 [99,] 6.143269e-02 3.827548e-03 8.873627e-01 4.737704e-02
[100,] 1.179641e-05 3.879116e-04 5.391678e-02 9.456835e-01

$error
[1] 0.14

$regparameters
                  3           4           5         6         7
intercept 0.8855278  0.91073034  0.96793471  0.969374  1.005703
1         0.5118310  2.01298787 -0.01485695 -1.023251  1.979198
2         1.0239138 -0.02352075  3.01144447  1.997734 -4.019287
                     8         9        10       11
intercept  0.842400074 0.8593035 0.8677248 0.899352
1          0.521734834 4.0069348 2.9883470 1.997643
2         -0.004344507 0.5107485 0.0266206 1.014451

attr(,&quot;class&quot;)
[1] &quot;selvarmix&quot;</code></pre>
<ul>
<li><a href="#top">Go to the top</a></li>
</ul>
<div id="refs" class="references">
<div id="ref-Maugis2009b">
<p>Maugis, C., G. Celeux, and M.-L. Martin-Magniette. 2009. “Variable Selection in Model-Based Clustering: A General Variable Role Modeling.” <em>Computational Statistics and Data Analysis</em> 53: 3872–82.</p>
</div>
<div id="ref-Maugis2011">
<p>———. 2011. “Variable Selection in Model-Based Discriminant Analysis.” <em>Journal of Multivariate Analysis</em> 102: 1374–87.</p>
</div>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
