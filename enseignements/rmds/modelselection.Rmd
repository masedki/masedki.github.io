---
title: "Sélection de modèle"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
---

## Sélection de modèle sur le jeu de données entier

On charge le package *leaps* et le jeu de données de rétinol plasmatique
```{r}
require(leaps)
load("~/Dropbox/enseignement/ml/Lectures/rmds/prostate.rda")
names(prostate)
```


On peut limiter le nombre de variables dans un modèle à tester via le paramètre *nvmax*

```{r}
regfit.full = regsubsets(lcavol~., data = prostate)
summary(regfit.full)
reg.summary = summary(regfit.full)
names(reg.summary)
```


```{r}
par(mfrow=c(2 ,2))
plot(reg.summary$rss , xlab =" Number of Variables " , ylab =" RSS " ,type ="l")
plot(reg.summary$adjr2 , xlab =" Number of Variables " , ylab =" Adjusted RSq " , type ="l")
which.max(reg.summary$adjr2)
points(which.max(reg.summary$adjr2), reg.summary$adjr2[which.max(reg.summary$adjr2)], col =" red " , cex =2 , pch =20)

plot(reg.summary$cp , xlab =" Number of Variables " , ylab =" Cp " ,type = "l")
which.min(reg.summary$cp)
points(which.min(reg.summary$cp), reg.summary$cp[which.min(reg.summary$cp)], col =" red " , cex =2 , pch =20)

plot(reg.summary$bic , xlab =" Number of Variables " , ylab =" BIC " , type ="l")
which.min(reg.summary$bic)
points(which.min(reg.summary$bic), reg.summary$bic[which.min(reg.summary$bic)], col =" red " , cex =2 , pch =20)
```

Le package *leap* possède sa propre fonction *plot*
```{r}
#plot(regfit.full , scale ="r2")
#plot(regfit.full , scale ="bic")
#plot(regfit.full , scale ="adjr2")
plot(regfit.full , scale ="Cp")

```

On peut accéder aux coefficient de régression du modèle à 1 variable 
```{r}
coef(regfit.full , 1)
```

On peut faire aussi de la recherche pas à pas en *forward* et *backward*
```{r}
regfit.fwd = regsubsets(lcavol~. , data = prostate, method ="forward")
summary(regfit.fwd)
plot(regfit.fwd, scale="bic")
```

```{r}
regfit.bwd = regsubsets(lcavol~. , data = prostate, method ="backward")
summary(regfit.bwd)
```

## Sélection de modèle avec des ensembles "apprentissage-validation" et validation croisée

On construit les deux ensembles *apprentissage* *validation* aléatoirement
```{r}
set.seed(1)
train = sample (c(TRUE,FALSE) , nrow(prostate), prob=c(2/3,1/3) , rep = TRUE)
test=(!train)
```

```{r}
regfit.best = regsubsets(lcavol~. , data = prostate[train,])
```

On peut récupérer la matrice dite de "design" du modèle complet sur les données de *validation*

```{r}
test.mat = model.matrix(lcavol~. , data = prostate[test,])
```

On va maintenant calculer l'erreur de prédiction sur l'ensemble de validation pour chaque nombre de variables dans le modèle
```{r}
val.errors = rep(NA ,8)
for( i in 1:8){
  coefi = coef(regfit.best,  id=i)
  pred = test.mat[ ,names(coefi)]%*%coefi
  val.errors[i]=mean((prostate$lcavol[test] - pred)^2)
}
val.errors
which.min(val.errors)
```

```{r}
coef(regfit.full, 1)
```

On a besoin d'une fonction qui prédit à partir d'un objet *regsubset*
```{r}
predict.regsubsets = function(object , newdata , id ,...){
form = as.formula(object$call[[2]])
mat = model.matrix( form , newdata)
coefi = coef(object , id=id)
xvars = names(coefi)
mat[ ,xvars]%*% coefi
}
```

On va faire une validation croisée à  5 *folds*
```{r}
k=5
set.seed(1)
folds = sample(1:k, nrow(prostate) , replace = TRUE)
cv.errors = matrix(NA, k, 8 ,dimnames = list(NULL , paste(1:8)))
```

```{r}
for(j in 1:k){
  best.fit = regsubsets(lcavol~. , data=prostate[folds!=j,] , nvmax=13)
  for (i in 1:8){
   pred = predict(best.fit , prostate[folds==j,] , id=i)
   cv.errors[j,i]= mean((prostate$lcavol[folds==j]-pred) ^2)
   }
 }
```
La moyenne de l'erreur sur les 5 folds
```{r}
mean.cv.errors = apply (cv.errors ,2 ,mean)
which.min(mean.cv.errors)
```


