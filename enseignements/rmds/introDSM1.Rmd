---
title: "Introduction aux data sciences"
output:
  html_document:
    theme: journal
    highlight: monochrome
    css: style.css
---

# Logiciel R et livre


<!-- - Pour une prise en main du logiciel R, je vous conseille vivement de travailler l'ensemble des exemples et exercices traités dans le [support](http://masedki.github.io/enseignements/pdfs/Introduction_to_R.pdf), initialement rédigé par Jean-Michel Marin et mis à jour par les deux autres auteurs. -->

- Pour ceux qui ont besoin d'indications, vous pouvez consulter [l'aide mémoire](http://masedki.github.io/enseignements/pdfs/RCarte_Commandes-R.pdf) de Julien Chiquet.

- Pour gagner en autonomie en programmation, la plateforme [stackoverflow](https://stackoverflow.com/) est indispensable^[Personnellement je consulte énormément cette plateforme où je trouve des réponses à mes questions.].

<!-- - [Support de cours](http://masedki.github.io/enseignements/pdfs/notes.pdf) (évolutif) à lire. Ce support couvre -->

<!--     - Introduction aux deux problèmes d'apprentissage : classification et régression -->

<!--     - Phénomène de sur-apprentissage -->

<!--     - Régression linéaire et régularisation -->

<!--     - Régression logistique et régularisation -->




- Le livre [*An Introduction to Statistical Learning*](http://masedki.github.io/enseignements/pdfs/ISLR.pdf) est indispensable. Ce livre a largement inspiré le contenu de ce cours !

# Introduction : régression, classification et phénomène de sur-apprentissage


**Séances du 10 et 17 février 2025 : ** traiter les exemples qu'on corrigera lors de la séance de cours. 

- [Code : séance d'introduction](http://masedki.github.io/enseignements/rcode/m1/code_intro.R) à traiter.

- [Code : validation croisée avec caret en classification](http://masedki.github.io/enseignements/rcode/m1/validation_croisee_knn_classif.R) à traiter.

- [Code : validation croisée avec caret en régression](http://masedki.github.io/enseignements/rcode/m1/validation_croisee_knn_reg.R) à traiter.

- Indispensables à lire pour cette partie (livre ISLR) : chapitres 1 et 2. 



**Séance du 25/02/2025 : ** Nous allons aborder les arbres de décision (brique de base d'un grand nombre de familles de modèles)

- Les [slides](http://masedki.github.io/enseignements/pdfs/m1sp/arbres.pdf)  et [notes](http://masedki.github.io/enseignements/pdfs/m1sp/trees.pdf) servent de supports des séances de cours sur les arbres de décision.

- ***À partir de cette séance, les scripts de TP doivent être codés en temps réel en séance de cours.***

- Indispensable à lire pour cette partie (livre ISLR) : chapitre 8 (8.1 pour les arbres et 8.2 pour les forêts aléatoires).



**Séance du 03/03/2025 : ** Nous allons aborder les arbres de décision pour la classification + retour sur l'élagage

- [Code : arbres de décision et élagage pour la régression](http://masedki.github.io/enseignements/rcode/m1/reg_trees.R) à traiter.


- [Code : arbres de décision et élagage pour la classification](http://masedki.github.io/enseignements/rcode/m1/classif_trees.R) à traiter.


**Séance du 10/03/2025 : ** Indice de Gini en classification + nous allons aborder les forêts aléatoires 


**Séance (si le temps le permet) : ** Nous allons aborder l'agrégation séquentielle d'arbre (boosting)

- Les [slides](http://masedki.github.io/enseignements/pdfs/m1sp/boosting_M1.pdf)

<!-- **Séance du lundi 06/03/2023:** Validation croisée sous R et introduction aux arbres de décision. [Slides de cours](http://masedki.github.io/enseignements/pdfs/arbres.pdf). -->

<!-- - Indispensables à lire (livre ISLR) : chapitre 5 (partie 1) pour la validation croisée et chapitre 8 (partie 1) pour une introduction aux arbres de décision.  Le chapitre 8 (Parties 8.2.1 et 8.2.2) pour le principe des forêts aléatoires.  -->
<!-- - [Arbre de décision pour la régression + RF](http://masedki.github.io/enseignements/rcode/reg_trees.R): Code pour la régression par arbre de décision avant et après élagage  + Random Forest. -->

<!-- - [Arbre de décision pour la classification + RF](http://masedki.github.io/enseignements/rcode/classif_trees.R): Code pour la classification par arbre de décision avant et après élagage  + Random Forest. -->


<!-- - [examen corrigé session 2 (2022)](http://masedki.github.io/enseignements/pdfs/m1sp/cs2_22.pdf). -->


<!-- # Régression : moindres carrés pour l'estimation des paramètres et choix de modèles -->

<!-- - **Séance du vendredi 14/02/2020:** lire la partie régression des [notes](http://masedki.github.io/enseignements/pdfs/notes.pdf) et traiter la partie 4.2 qu'on corrigera en cours. Attention la partie régression de ces notes ne peut constituer un cours abouti de modèle linéaire. [Code R](http://masedki.github.io/enseignements/rcode/code_reg_ridge_lasso_enet.R) : détails des exemples traités. -->

<!-- Lecture conseillée : Les parties 3.1 et 3.2 du [livre](http://masedki.github.io/enseignements/pdfs/ISLR.pdf)   *An Introduction to Statistical Learning* sont indispensables pour l'assimilation des fondements des modèles linéaires et en particulier la partie inférence statistique.^[Pour l'inférence statistique, penser aux tests et intervalles de confiance pour les paramètres de régression.] -->

<!-- # Méthodes de régularisation : ridge, lasso et elasticnet -->

<!-- - **Séance du vendredi 14/02/2020:** lire les parties régularisation ridge, lasso et -->
<!-- elasticnet. Traiter les exemples autour du jeu de données du cancer de la prostate. [Code R](http://masedki.github.io/enseignements/rcode/code_reg_ridge_lasso_enet.R): ridge, lasso et elasticnet sur le jeu de données Prostate. -->

<!-- Lecture fortement conseillée : chapitre 6. du livre *An Introduction to Statistical Learning*. -->

<!-- - **Séance du vendredi 21/02/2020: (si le temps le permet)**   Méthodes de régularisation en régression logistique.  Traiter l'exemple  *Sélection de variables en régression logistique : jeu de données Breast Cancer* page 33. -->

<!-- [Code R 1](http://masedki.github.io/enseignements/rcode/code_logit_enet.R): Code pour la régression logistique et régression logistique avec régularisation elasticnet. -->



<!-- [Code R 2](http://masedki.github.io/enseignements/rcode/classif_image_logit_enet.R): Code pour la régression logistique avec régularisation elasticnet pour la classifiction d'images. (attention le code est très lent donc je vais déposer les résultats rapidement après calcul sur un serveur).  -->


<!-- # Arbres de décision : régression -->
<!-- - **Séance du vendredi 19/02/2021:**  Arbres de décision unique : supports de cours disponibles [ici](http://masedki.github.io/enseignements/pdfs/arbres_agregation_m1.pdf). -->


<!-- [Code R](http://masedki.github.io/enseignements/rcode/rpart_insurance.R): Code pour la régression par arbre de décision avant et après élagage et comparaison avec le régression avec régularisation elasticnet. Attention : présence de données catégorielles donc traitement particulier pour l'elasticnet (voir lignes 40 et 41 du code). -->

<!-- Lecture conseillée : Lecture de la partie 8.1 et Lab de la partie 8.3.1 du livre *An Introduction to Statistical Learning*. -->


<!-- # Arbres de décision : classification -->

<!-- **Séance du mercredi 26/02/2021:** classification par arbre de décision. -->

<!-- [Code R](http://masedki.github.io/enseignements/rcode/rpart_pima.R): Code pour la classification par arbre de décision avant et après élagage et comparaison avec le régression logistique avec régularisation elasticnet. -->

<!-- Lecture conseillée : Lecture de la partie 8.1 et  Lab de la partie 8.3.2 du livre *An Introduction to Statistical Learning*. -->




<!-- # Méthodes de régularisation : ridge, lasso et elasticnet -->

<!-- **Séance du vendredi 05/03/2021:** lire les parties régularisation ridge, lasso et -->
<!-- elasticnet. Traiter les exemples autour du jeu de données du cancer de la prostate. [Code R](http://masedki.github.io/enseignements/rcode/code_reg_ridge_lasso_enet.R): ridge, lasso et elasticnet sur le jeu de données Prostate.  -->


<!-- **Séance du vendredi 12/03/2021:**   Méthodes de régularisation en régression logistique.  Traiter l'exemple  *Sélection de variables en régression logistique : jeu de données Breast Cancer* page 33. -->

<!-- [Code R](http://masedki.github.io/enseignements/rcode/code_logit_enet.R): Code pour la régression logistique et régression logistique avec régularisation elasticnet. -->


<!-- # [Examen de seconde session à rendre avant le 07/09/2020](http://masedki.github.io/enseignements/cc2.html)  -->

<!-- # Projet  : Utilisation de la librairie caret (sixième partie des notes)   -->

<!-- À rendre au plus tard le dimanche 2 juin à 23h par mail avec un fichier .R ou .rmd contenant le code et les réponses en commentaire. Mettre les affichages de vos résultats en commentaire -->
<!-- dans votre script. Les affichages des résultats me permettront de comprendre les conclusions et les réponses. -->
<!-- [corrigé](http://masedki.github.io/enseignements/cc_correction.html) -->


[Examen 2021](http://masedki.github.io/enseignements/pdfs/s1_2021.pdf) juin 2021

[Examen 2024 (vous n'avez pas vu adaboost cette année)](http://masedki.github.io/enseignements/pdfs/exmen_M1_24.pdf) juin 2024

<!-- # [Projet pour la seconde session](http://masedki.github.io/enseignements/pdfs/cc2.pdf) à rendre au plus tard le 03/09/2019 à 23h.  -->


Si besoin, le package R [ElemStatLearn](http://masedki.github.io/enseignements/rcode/ElemStatLearn_2015.6.26.2.tar.gz)




[Jeu de données mixture example](https://masedki.github.io/enseignements/datasets/mixture_example.rda)
<!-- [Jeu de données mnist aplati !](http://masedki.github.io/enseignements/datasets/mnist_flatten.rda) -->

[Jeu de données coûts de soins](http://masedki.github.io/enseignements/datasets/insurance.rda)

<!-- [Jeu de données crédit](http://masedki.github.io/enseignements/datasets/credit.rda) -->

<!-- [Jeu de données spams](http://masedki.github.io/enseignements/datasets/dataspam.rda) -->

<!-- [Projet pour le parcours MSP/ES](http://masedki.github.io/enseignements/pdfs/mspes.pdf) -->