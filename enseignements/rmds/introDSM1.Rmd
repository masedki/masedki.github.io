---
title: "Introduction aux data sciences"
output:
  html_document:
    theme: journal
    highlight: monochrome
    css: style.css
---

# Logiciel R 


- Pour une prise en main en R, je vous conseille vivement de travailler l'ensemble des exemples et exercices traités dans le [support](http://masedki.github.io/enseignements/pdfs/Introduction_to_R.pdf), initialement rédigé par Jean-Michel Marin et 
mis à jour par les deux autres auteurs. 

- Pour ceux qui ont besoin d'indications ponctuelles, vous pouvez consulter [l'aide mémoire](http://masedki.github.io/enseignements/pdfs/RCarte_Commandes-R.pdf) de Julien Chiquet.  

- Pour gagner en autonomie en programmation, la plateforme [stackoverflow](https://stackoverflow.com/) est indispensable^[Personnellement je consulte énormément cette plateforme où je trouve des réponses à mes questions.].

- [Support](http://masedki.github.io/enseignements/pdfs/notes.pdf) (évolutif) à lire. 
- Le chapitre 5 du [livre](http://masedki.github.io/enseignements/pdfs/ISLR.pdf) est indispensable et s'applique à chaque partie
 (méthode d'apprentissage) de ce cours. 

# Introduction : régression, classification et phénomène de sur-apprentissage

- **Séance du vendredi 15/02/2019:** traiter les exemples qu'on corrigera lors de la séance de cours. [Codes R](http://masedki.github.io/enseignements/rcode/code_intro.R) issu de la première séance. Les détails de chaque instruction sont données en commentaires
précédés par un #. 

# Régression : moindres carrés pour l'estimation des paramètres et choix de modèles

- **Séance du vendredi 08/03/2019:** lire la partie régression des [notes](http://masedki.github.io/enseignements/pdfs/notes.pdf) et traiter la partie 4.2 qu'on corrigera en cours. Attention la partie régression de ces notes ne peut constituer un cours de modèle linéaire classique. Les parties 3.1 et 3.2 du [livre](http://masedki.github.io/enseignements/pdfs/ISLR.pdf) sont indispensables pour l'assimilation des fondements des modèles linéaires et en particulier la partie inférence statistique^[Pour l'inférence statistique, penser aux tests et intervalles de confiance pour les paramètres de régression.]. [Code R](http://masedki.github.io/enseignements/rcode/code_reg_ridge_lasso_enet.R) : détails des exemples traités.


# Méthodes de régularisation : ridge, lasso et elasticnet

- **Séance du vendredi 15/03/2019:** lire les parties régularisation ridge, lasso et
elasticnet. Traiter les exemples autour du jeu de données du cancer de la prostate. [Code R](http://masedki.github.io/enseignements/rcode/code_reg_poly.R): ridge, lasso et elasticnet sur le jeu de données Prostate

- **Séance du vendredi 12/04/2019:**  Méthodes de régularisation en régression logistique.  Traiter l'exemple  *Sélection de variables en régression logistique : jeu de données Breast Cancer* page 33.

# Projet  : Utilisation de la librairie caret (sixième partie des notes)  

À rendre au plus tard le dimanche 2 juin à 23h par mail avec un fichier .R ou .rmd contenant le code et les réponses en commentaire. Mettre les affichages de vos résultats en commentaire
dans votre script. Les affichages des résultats me permettront de comprendre les conclusions et les réponses.  


<!-- [Jeu de données bes](http://masedki.github.io/enseignements/datasets/bes.dta) -->

<!-- [Jeu de données crédit](http://masedki.github.io/enseignements/datasets/credit.rda) -->

<!-- [Jeu de données spams](http://masedki.github.io/enseignements/datasets/dataspam.rda) -->

<!-- [Projet pour le parcours MSP/ES](http://masedki.github.io/enseignements/pdfs/mspes.pdf) -->